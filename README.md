# Wikishop_project_working_with_text
<br>
<font color='black' size=6> <b>Проект для «Викишоп»</b></font>
<br><br>
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества *F1* не меньше 0.75. 

**Инструкция по выполнению проекта**

1. Загрузите и подготовьте данные.
2. Обучите разные модели. 
3. Сделайте выводы.

Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

___
<a id="start"></a><br>
<font color='black' size=6> <b> Содержание</b></font><br><br>


<font color='black' size=5> <b>1. Подготовка данных</b></font><br>


   * <a href='#step_1'> Загружаем библиотеки </a>
   * <a href='#step_1.1'> Откроем файл и изучим его </a>
          - Путь к файлу: (/datasets/toxic_comments.csv)
   * <a href='#step_1.2'> Лемматизируем текст и избавим его от лишних символов </a>
       * <a href='#step_1.2.1'>Загрузим библиотеку для обработи текста </a>
       * <a href='#step_1.2.2'> Создадим функцию по очистке данных</a>
       * <a href='#step_1.2.3'> Создадим функцию которая будет использовать функцию по очистке слов и лемматизировать каждое слово</a>
   * <a href='#step_1.3'> Посмотрим на распределение классов в данных</a>
   * <a href='#step_1.4'> Разделим выборки</a>
      * <a href='#step_1.4.1'> Проверим распределение класов в *тренировочной* выборке</a>
      * <a href='#step_1.4.2'> Проверим распределение класов в *тестовой* выборке</a>
      * <a href='#step_1.4.3'> Создадим функцию, для увеличения выборки по первому [1] классу данных и уменьшению выборки по нулевому [0] классу</a>
   * <a href='#step_1.5'> Используем технологию TF-IDF для обработки наших данны, а так же отфильтруем содержимое при помощи библиотеки `nltk`</a>
   * <a href='#step_1.end'> Вывод </a><br><br>

<font color='black' size=5> <b>2. Обучение</b></font><br>

   * <a href='#step_2'> Создадим функцию для вывода графика плотности распределения предсказанных и истинных значений </a>
   * <a href='#step_2.1'> Создадим функцию для вывода матрицы предсказаний</a>
   * <a href='#step_2.2'> Обучим модель `DecisionTreeClassifier`</a>
   * <a href='#step_2.3'> Обучим модель `LogisticRegression`</a>
   * <a href='#step_2.4'> Обучим модель `RandomForestClassifier`</a>
   * <a href='#step_2.5'> Определим порог классификации для наилучшей модели `LogisticRegression`</a>
   * <a href='#step_2.6'> Проверим выбранный порог для нашей модели</a>
   * <a href='#step_2.7'> Вычислим ROC-AUC для наилучшей модели </a>
  
   * <a href='#step_2.end'> Вывод </a> <br><br>  
      

<font color='black' size=5> <b>3. Общий вывод</b></font><br>


   * <a href='#step_3.end'> Вывод </a>
<br><br>
<font color='orange'><u>INFO</u>:<font color='gray'> При запуске ячеек, запустить <font color='green'><b><i>"Restart & Run All"

----
----
