# Проект для интернет-магазина «Викишоп» 
<!--- ![image](https://user-images.githubusercontent.com/76148212/122682089-2bb44700-d200-11eb-8afe-023f9698fd59.png) -->

## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

## Задача:
Ускорить модерацию комментариев в сообществе, автоматизировав оценку их токсичности.
Обучить модель классифицировать комментарии на позитивные и негативные.
Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.
Постройте модель со значением метрики качества *F1* не меньше 0.75. 

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## Инструменты:
`Pandas`
`sklearn`
`numpy`
`NLTK`
`LightGBM`
`CatBoost`
`машинное обучение`

## Краткое описание проведённой работы:
<i>Для запуска нового сервиса интернет-магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. 
Обучена модель классифицировать комментарии на позитивные и негативные. Проанализирован набор данных с разметкой о токсичности правок.
Построена модель со значением метрики качества F1 не меньше 0.75.
К текстам и временным рядам применена техника feature engineering. 
Векторизированы тексты посредством word2vec, GloVe, FastText. </i>

## Данные и выводы
<i>Для определения наилучшей модели мы остановили наш выбор на трёх моделях DecisionTreeClassifier,LogisticRegression и RandomForestClassifier. По итогам сравнеиня победила модель LogisticRegression и после побора порогового значения, набрала значение метрики F1=0.77</i>

---

#### Если проект не открывается, его можно просмотреть по ссылке: <a href='https://nbviewer.jupyter.org/github/AxelVas/Wikishop_project_working_with_text/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82_%27%D0%92%D0%B8%D0%BA%D0%B8%D1%88%D0%BE%D0%BF%27_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%D1%81_%D0%BA%D0%BE%D0%BC%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%B8%D1%8F%D0%BC%D0%B8.ipynb'>Wikishop_project_working_with_text</a>

<!--- 
___
## Полное содержание проекта <br>


<font color='black' size=5> <b>1. Подготовка данных</b></font><br>


   * <a href='#step_1'> Загружаем библиотеки </a>
   * <a href='#step_1.1'> Откроем файл и изучим его </a>
          - Путь к файлу: (/datasets/toxic_comments.csv)
   * <a href='#step_1.2'> Лемматизируем текст и избавим его от лишних символов </a>
       * <a href='#step_1.2.1'>Загрузим библиотеку для обработи текста </a>
       * <a href='#step_1.2.2'> Создадим функцию по очистке данных</a>
       * <a href='#step_1.2.3'> Создадим функцию которая будет использовать функцию по очистке слов и лемматизировать каждое слово</a>
   * <a href='#step_1.3'> Посмотрим на распределение классов в данных</a>
   * <a href='#step_1.4'> Разделим выборки</a>
      * <a href='#step_1.4.1'> Проверим распределение класов в *тренировочной* выборке</a>
      * <a href='#step_1.4.2'> Проверим распределение класов в *тестовой* выборке</a>
      * <a href='#step_1.4.3'> Создадим функцию, для увеличения выборки по первому [1] классу данных и уменьшению выборки по нулевому [0] классу</a>
   * <a href='#step_1.5'> Используем технологию TF-IDF для обработки наших данны, а так же отфильтруем содержимое при помощи библиотеки `nltk`</a>
   * <a href='#step_1.end'> Вывод </a><br><br>

<font color='black' size=5> <b>2. Обучение</b></font><br>

   * <a href='#step_2'> Создадим функцию для вывода графика плотности распределения предсказанных и истинных значений </a>
   * <a href='#step_2.1'> Создадим функцию для вывода матрицы предсказаний</a>
   * <a href='#step_2.2'> Обучим модель `DecisionTreeClassifier`</a>
   * <a href='#step_2.3'> Обучим модель `LogisticRegression`</a>
   * <a href='#step_2.4'> Обучим модель `RandomForestClassifier`</a>
   * <a href='#step_2.5'> Определим порог классификации для наилучшей модели `LogisticRegression`</a>
   * <a href='#step_2.6'> Проверим выбранный порог для нашей модели</a>
   * <a href='#step_2.7'> Вычислим ROC-AUC для наилучшей модели </a>
  
   * <a href='#step_2.end'> Вывод </a> <br><br>  
      

<font color='black' size=5> <b>3. Общий вывод</b></font><br>


   * <a href='#step_3.end'> Вывод </a>
<br><br>
<font color='orange'><u>INFO</u>:<font color='gray'> При запуске ячеек, запустить <font color='green'><b><i>"Restart & Run All"

----
----
